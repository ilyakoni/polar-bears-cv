{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/obss/sahi\n",
    "\n",
    "# !git clone https://github.com/pytorch/vision.git\n",
    "# !cd vision\n",
    "# !cp references/detection/engine.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from sahi.model import TorchVisionDetectionModel\n",
    "from sahi.predict import get_sliced_prediction, predict, get_prediction\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.utils.cv import read_image\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасетов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarBearsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"bears\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"bears\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = np.array(mask)\n",
    "        # mask[mask != 0] = 1\n",
    "        \n",
    "\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "        \n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        # masks = mask == obj_ids[:]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            # masks = mask == obj_ids[i]\n",
    "\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            # if any([i % 1 != 0 for i in [xmin, ymin, xmax, ymax]]):\n",
    "                # print(boxes)\n",
    "            # if xmin == xmax or ymin == ymax:\n",
    "            #     print([xmin, ymin, xmax, ymax])\n",
    "                # continue\n",
    "\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # boxes = torch.as_tensor(boxes, dtype=torch.int64)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            # img, target = self.transforms(img, target)\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    # if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        # transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = PolarBearsDataset('CroppedBearsDataset/', get_transform(train=True))\n",
    "dataset_test = PolarBearsDataset('CroppedBearsDataset/', get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoenkCj18C4h"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "at-h4OWK0aoc",
    "outputId": "ab6753bc-6251-42e5-d65b-32efec93c61e"
   },
   "outputs": [],
   "source": [
    "# let's train it for 10 epochs\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform(False)\n",
    "# test_img = Image.open('testing_ultra_set/183.png')\n",
    "test_img = Image.open('PolarBearsDataset/arctic_with_bears/bears/14.JPG')\n",
    "test_img = transform(test_img)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([test_img.to(device)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(test_img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['masks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHwIdxH76uPj"
   },
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "img, _ = dataset_test[8]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lkmb3qUu6zw3",
    "outputId": "7e876402-3a0f-4696-a13e-6ddcabb5fb77"
   },
   "outputs": [],
   "source": [
    "prediction[0]['masks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "bpqN9t1u7B2J",
    "outputId": "b998eca7-5e3c-4ea6-ccfc-052fef26c5a0"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "5v5S3bm07SO1",
    "outputId": "89e92ecd-dbca-4939-fb94-8d2f1b3a7cc1"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][2, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "model_path = \"polar_bear_maskrcnn_resnet50_fpn_v1.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"polar_bear_maskrcnn_resnet50_fpn_v1.pt\"\n",
    "\n",
    "model = torch.load(path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_detection_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    # if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        # transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = PolarBearsDataset('CroppedBearsDataset/', get_transform(train=True))\n",
    "dataset_test = PolarBearsDataset('CroppedBearsDataset/', get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoenkCj18C4h"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_detection_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "at-h4OWK0aoc",
    "outputId": "ab6753bc-6251-42e5-d65b-32efec93c61e"
   },
   "outputs": [],
   "source": [
    "# let's train it for 10 epochs\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform(False)\n",
    "# test_img = Image.open('testing_ultra_set/183.png')\n",
    "test_img = Image.open('PolarBearsDataset/arctic_with_bears/bears/14.JPG')\n",
    "test_img = transform(test_img)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([test_img.to(device)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(test_img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['masks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHwIdxH76uPj"
   },
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "img, _ = dataset_test[8]\n",
    "\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "bpqN9t1u7B2J",
    "outputId": "b998eca7-5e3c-4ea6-ccfc-052fef26c5a0"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['boxes'].to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "img = img.to(torch.uint8)\n",
    "\n",
    "for box in prediction[0]['boxes']:\n",
    "    img = draw_bounding_boxes(img, box, width=5,\n",
    "                          colors=\"green\", \n",
    "                          fill=True)\n",
    "\n",
    "img = torchvision.transforms.ToPILImage()(img)\n",
    "  \n",
    "# display output\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем функцию для показа картинки, так будет удобнее\n",
    "def show_img(img, resize=(512, 512)):\n",
    "    # переводим тип массива в unsigned int 8\n",
    "    # этот тип может представлять числа в диапазоне (0, 255), \n",
    "    # поэтому он идеален для представления картинок\n",
    "    img = img.astype(\"uint8\")\n",
    "    \n",
    "    # если понадобится, то можем изменить размер картинки\n",
    "    if resize:\n",
    "        img = cv2.resize(img, resize)\n",
    "\n",
    "    # составляем картинку из массива и возвращаем её\n",
    "    # если вызвать эту функции в конце ячейки, то изображении автоматически покажется в ноутбуке\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['boxes'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.mul(255).permute(1, 2, 0).byte().numpy()\n",
    "img = img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in prediction[0]['boxes']:\n",
    "    box = box.cpu().numpy().astype(int)\n",
    "    img = cv2.rectangle(img, (box[0], box[1]),\n",
    "                             (box[2], box[3]),\n",
    "                             (255, 0, 0), 1)\n",
    "   \n",
    "\n",
    "show_img(img, resize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "5v5S3bm07SO1",
    "outputId": "89e92ecd-dbca-4939-fb94-8d2f1b3a7cc1"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['boxes'][0, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "model_path = \"polar_bear_fasterrcnn_resnet50_fpn_v1.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"polar_bear_fasterrcnn_resnet50_fpn_v1.pt\"\n",
    "\n",
    "model = torch.load(path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAHI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = TorchVisionDetectionModel(\n",
    "    model=model,\n",
    "    confidence_threshold=0.99,\n",
    "    image_size=800,\n",
    "    # device=\"cpu\",\n",
    "    device=\"cuda:0\",\n",
    "    load_at_init=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Без SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = get_prediction(\"CroppedBearsDataset/bears/0.png\", detection_model)\n",
    "result = get_prediction(\"PolarBearsDataset/arctic_with_bears/bears/1.JPG\", detection_model)\n",
    "# result = get_prediction(read_image(\"CroppedBearsDataset/bears/0.png\"), detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals(export_dir=\"demo_data/\")\n",
    "\n",
    "display.Image(\"demo_data/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Со слайсингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = \"PolarBearsDataset/arctic_with_bears/bears/5.jpg\"\n",
    "# im = \"unknown1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_sliced_prediction(\n",
    "    im,\n",
    "    detection_model,\n",
    "    slice_height = 800,\n",
    "    slice_width = 800,\n",
    "    overlap_height_ratio = 0.1,\n",
    "    overlap_width_ratio = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals(export_dir=\"demo_data/\")\n",
    "\n",
    "display.Image(\"demo_data/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка нескольких фотографий одновременно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"torchvision\"\n",
    "model_device = 'cuda:0'\n",
    "# model_device = \"cpu\"\n",
    "model_confidence_threshold = 0.99\n",
    "model_input_size = 800\n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detection_model = TorchVisionDetectionModel(\n",
    "    model=model,\n",
    "    confidence_threshold=model_confidence_threshold,\n",
    "    image_size=model_input_size,\n",
    "    device=model_device, \n",
    "    load_at_init=True,\n",
    ")\n",
    "\n",
    "slice_height = 800\n",
    "slice_width = 800\n",
    "overlap_height_ratio = 0.1\n",
    "overlap_width_ratio = 0.1\n",
    "\n",
    "# source_image_dir = \"PolarBearsDataset/arctic_with_bears/bears/\"\n",
    "source_image_dir = \"check\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\n",
    "    model_type=model_type,\n",
    "    detection_model=detection_model,\n",
    "    source=source_image_dir,\n",
    "    slice_height=slice_height,\n",
    "    slice_width=slice_width,\n",
    "    overlap_height_ratio=overlap_height_ratio,\n",
    "    overlap_width_ratio=overlap_width_ratio,\n",
    "    project='test',\n",
    "    name='1',\n",
    "    export_pickle=True,\n",
    "    # novisual=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 медведя не были найдены, 1 медведь найден с уверенностью 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test/1/pickles/'\n",
    "items = len(os.listdir(path))\n",
    "\n",
    "for i in range(items):\n",
    "    obj = pd.read_pickle(path+str(i)+'.pickle')\n",
    "    bboxes = [i.to_coco_annotation().bbox for i in obj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связка с интерфейсом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем функцию для показа картинки, так будет удобнее\n",
    "def show_img(img, resize=(512, 512)):\n",
    "    # переводим тип массива в unsigned int 8\n",
    "    # этот тип может представлять числа в диапазоне (0, 255), \n",
    "    # поэтому он идеален для представления картинок\n",
    "    img = img.astype(\"uint8\")\n",
    "    \n",
    "    # если понадобится, то можем изменить размер картинки\n",
    "    if resize:\n",
    "        img = cv2.resize(img, resize)\n",
    "\n",
    "    # составляем картинку из массива и возвращаем её\n",
    "    # если вызвать эту функции в конце ячейки, то изображении автоматически покажется в ноутбуке\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox, color=(255, 0, 0), thickness=10):\n",
    "    # img = img.copy()\n",
    "    return cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), color=color, thickness=thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"torchvision\"\n",
    "model_device = 'cuda:0'\n",
    "# model_device = \"cpu\"\n",
    "model_confidence_threshold = 0.99\n",
    "model_input_size = 800\n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detection_model = TorchVisionDetectionModel(\n",
    "    model=model,\n",
    "    confidence_threshold=model_confidence_threshold,\n",
    "    image_size=model_input_size,\n",
    "    device=model_device, \n",
    "    load_at_init=True,\n",
    ")\n",
    "\n",
    "slice_height = 800\n",
    "slice_width = 800\n",
    "overlap_height_ratio = 0.1\n",
    "overlap_width_ratio = 0.1\n",
    "\n",
    "# source_image_dir = \"PolarBearsDataset/arctic_with_bears/bears/\"\n",
    "# source_image_dir = \"check\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\n",
    "    model_type=model_type,\n",
    "    detection_model=detection_model,\n",
    "    source='PolarBearsDataset/AppTest',\n",
    "    slice_height=slice_height,\n",
    "    slice_width=slice_width,\n",
    "    overlap_height_ratio=overlap_height_ratio,\n",
    "    overlap_width_ratio=overlap_width_ratio,\n",
    "    project='AppTest',\n",
    "    name='first',\n",
    "    export_pickle=True,\n",
    "    # novisual=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'AppTest/first/pickles/'\n",
    "items = len(os.listdir(path))\n",
    "\n",
    "# bboxes_list = []\n",
    "\n",
    "for i in range(items):\n",
    "    # img = Image.open('PolarBearsDataset/AppTest/'+str(i)+'.jpg')\n",
    "    img = cv2.imread('PolarBearsDataset/AppTest/'+str(i)+'.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    obj = pd.read_pickle(path+str(i)+'.pickle')\n",
    "    bboxes = [i.to_coco_annotation().bbox for i in obj]\n",
    "    if bboxes:\n",
    "        for bb in bboxes:\n",
    "            draw_bbox(img, bb)\n",
    "        Image.fromarray(img).save('output/' + str(i) + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('PolarBearsDataset/AppTest/8.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('PolarBearsDataset/AppTest/8.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(draw_bbox(img, bboxes_list[0][0]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'IMG'\n",
    "\n",
    "# for name in os.listdir(path):\n",
    "#     if name.endswith(\".JPG\"):\n",
    "#         os.rename(path + '/' + name, path + '/' + name.split('.')[0] + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"torchvision\"\n",
    "model_device = 'cuda:0'\n",
    "# model_device = \"cpu\"\n",
    "model_confidence_threshold = 0.99\n",
    "model_input_size = 800\n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detection_model = TorchVisionDetectionModel(\n",
    "    model=model,\n",
    "    confidence_threshold=model_confidence_threshold,\n",
    "    image_size=model_input_size,\n",
    "    device=model_device, \n",
    "    load_at_init=True,\n",
    ")\n",
    "\n",
    "slice_height = 800\n",
    "slice_width = 800\n",
    "overlap_height_ratio = 0.1\n",
    "overlap_width_ratio = 0.1\n",
    "\n",
    "# source_image_dir = \"PolarBearsDataset/arctic_with_bears/bears/\"\n",
    "# source_image_dir = \"check\"\n",
    "source_image_dir = 'IMG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\n",
    "    model_type=model_type,\n",
    "    detection_model=detection_model,\n",
    "    source=source_image_dir,\n",
    "    slice_height=slice_height,\n",
    "    slice_width=slice_width,\n",
    "    overlap_height_ratio=overlap_height_ratio,\n",
    "    overlap_width_ratio=overlap_width_ratio,\n",
    "    project='submit',\n",
    "    name='test1',\n",
    "    export_pickle=True,\n",
    "    # novisual=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centres(bbxs, num):\n",
    "    names = []\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for bb in bbxs:\n",
    "        x, y = (bb[0] - bb[2] // 2), (bb[1] - bb[3] // 2)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        names.append(f\"{num}.JPG\")\n",
    "\n",
    "    return names, x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "path = 'submit/test1/pickles/'\n",
    "items = len(os.listdir(path))\n",
    "\n",
    "for i in range(items):\n",
    "    obj = pd.read_pickle(path+str(i)+'.pickle')\n",
    "    bboxes = [i.to_coco_annotation().bbox for i in obj][:3]\n",
    "    \n",
    "    nam, x, y = find_centres(bboxes, i)\n",
    "\n",
    "    names += nam\n",
    "    x_list += x\n",
    "    y_list += y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(dict(name=names, x=x_list, y=y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"deviants.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b211e5f61c7b470ea22bbed36c4ce59cc72bd864d3781abf4b22fb8a404a9806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
